{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Covered\n",
    "\n",
    "• Preprocessing Data for NN • FFNN for Binary Classification • FFNN for Multi-Class Classification • FFNN for Regression        • Convolutional Neural Networks \n",
    "• Visualize Loss History  • Visualize network Architecture • NN Weight Regularization(L2) • Dropout • LSTM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data for NN\n",
    "\n",
    "Typically, a neural network’s parameters are initialized (i.e. created) as small random numbers. Neural networks often behave poorly when the feature values much larger than parameter values. Furthermore, since an observation’s feature values will are combined as they pass through individual units, it is important that all features have the same scale.\n",
    "\n",
    "For these reasons, it is best practice (although not always necessary, for example when we have all binary features) to standardize each feature such that the feature’s values have the mean of 0 and the standard deviation of 1. This can be easily accomplished using scikit-learn’s StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature\n",
    "features = np.array([[-100.1, 3240.1], \n",
    "                     [-200.2, -234.1], \n",
    "                     [5000.5, 150.1], \n",
    "                     [6000.6, -125.1], \n",
    "                     [9000.9, -673.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Transform the feature\n",
    "features_standardized = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Standard deviation: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation\n",
    "print('Mean:', round(features_standardized[:,0].mean()))\n",
    "print('Standard deviation:', features_standardized[:,0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFNN for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras IMDB Dataset\n",
    "\n",
    "The info about keras imdb dataset is available [here](http://localhost:8888/edit/Desktop/Python_revision/Chris_Albon_Blog_Prac/Imdb_info.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Feedforward Neural Network\n",
    "In Keras, we train our neural network using the fit method. There are six significant parameters to define. The first two parameters are the features and target vector of the training data.\n",
    "\n",
    "The epochs parameter defines how many epochs to use when training the data. verbose determines how much information is outputted during the training process, with 0 being no out, 1 outputting a progress bar, and 2 one log line per epoch. batch_size sets the number of observations to propagate through the network before updating the parameters.\n",
    "\n",
    "Finally, we held out a test set of data to use to evaluate the model. These test features and test target vector can be arguments of the validation_data, which will use them for evaluation. Alternatively, we could have used validation_split to define what fraction of the training data we want to hold out for evaluation.\n",
    "\n",
    "In scikit-learn fit method returned a trained model, however in Keras the fit method returns a History object containing the loss values and performance metrics at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 3s 137us/step - loss: 0.4195 - accuracy: 0.8120 - val_loss: 0.3394 - val_accuracy: 0.8546\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 0.3225 - accuracy: 0.8641 - val_loss: 0.3284 - val_accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 2s 95us/step - loss: 0.3107 - accuracy: 0.8691 - val_loss: 0.3392 - val_accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=1, # Print description after each epoch\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward Neural Network For Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reuters newswire classification dataset\n",
    "### different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 15s 7us/step\n"
     ]
    }
   ],
   "source": [
    "# Set the number of features we want\n",
    "number_of_features = 5000\n",
    "\n",
    "# Load feature and target data\n",
    "(train_data, train_target_vector), (test_data, test_target_vector) = reuters.load_data(num_words=number_of_features)\n",
    "\n",
    "# Convert feature data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\n",
    "\n",
    "# One-hot encode target vector to create a target matrix\n",
    "train_target = to_categorical(train_target_vector)\n",
    "test_target = to_categorical(test_target_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_target[0])  ###Implies one hot encoding has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100, activation='relu', input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units=46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='categorical_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 3s 279us/step - loss: 0.3581 - accuracy: 0.9200 - val_loss: 0.9212 - val_accuracy: 0.7961\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 2s 229us/step - loss: 0.2665 - accuracy: 0.9400 - val_loss: 0.9495 - val_accuracy: 0.8001\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 3s 282us/step - loss: 0.2239 - accuracy: 0.9454 - val_loss: 0.9950 - val_accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=3, # Three epochs\n",
    "                      verbose=1, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data to use for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFNN for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features = 3,\n",
    "                                   n_informative = 3,\n",
    "                                   n_targets = 1,\n",
    "                                   noise = 0.0,\n",
    "                                   random_state = 0)\n",
    "\n",
    "# Divide our data into training and test sets\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.33, \n",
    "                                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create NN Architecture\n",
    "##Start NN\n",
    "network = models.Sequential()\n",
    "\n",
    "##Add fully connected layer with ReLu activation\n",
    "network.add(layers.Dense(units = 32,activation = 'relu',input_shape = (train_features.shape[1],)))\n",
    "\n",
    "###Add another fully connected layer with relu activation\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='mse', # Mean squared error\n",
    "                optimizer='RMSprop', # Optimization algorithm\n",
    "                metrics=['mse']) # Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6700 samples, validate on 3300 samples\n",
      "Epoch 1/10\n",
      "6700/6700 [==============================] - 2s 262us/step - loss: 17232.3343 - mse: 17232.3320 - val_loss: 17555.8796 - val_mse: 17555.8770\n",
      "Epoch 2/10\n",
      "6700/6700 [==============================] - 0s 33us/step - loss: 16329.4387 - mse: 16329.4375 - val_loss: 16272.0335 - val_mse: 16272.0342\n",
      "Epoch 3/10\n",
      "6700/6700 [==============================] - 0s 31us/step - loss: 14701.0309 - mse: 14701.0293 - val_loss: 14176.7801 - val_mse: 14176.7832\n",
      "Epoch 4/10\n",
      "6700/6700 [==============================] - 0s 30us/step - loss: 12346.3557 - mse: 12346.3574 - val_loss: 11334.1993 - val_mse: 11334.1973\n",
      "Epoch 5/10\n",
      "6700/6700 [==============================] - 0s 30us/step - loss: 9302.8076 - mse: 9302.8076 - val_loss: 7940.3479 - val_mse: 7940.3477\n",
      "Epoch 6/10\n",
      "6700/6700 [==============================] - 1s 117us/step - loss: 5983.1162 - mse: 5983.1157 - val_loss: 4496.0978 - val_mse: 4496.0977\n",
      "Epoch 7/10\n",
      "6700/6700 [==============================] - 0s 30us/step - loss: 2952.9411 - mse: 2952.9409 - val_loss: 1801.2676 - val_mse: 1801.2678\n",
      "Epoch 8/10\n",
      "6700/6700 [==============================] - 0s 30us/step - loss: 1007.9844 - mse: 1007.9843 - val_loss: 510.6358 - val_mse: 510.6359\n",
      "Epoch 9/10\n",
      "6700/6700 [==============================] - 0s 29us/step - loss: 371.3809 - mse: 371.3809 - val_loss: 285.1302 - val_mse: 285.1302\n",
      "Epoch 10/10\n",
      "6700/6700 [==============================] - 0s 30us/step - loss: 264.2216 - mse: 264.2216 - val_loss: 237.1971 - val_mse: 237.1971\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=10, # Number of epochs\n",
    "                      verbose=1, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network Architecture\n",
    "Convolutional neural networks (also called ConvNets) are a popular type of network that has proven very effective at computer vision (e.g. recognizing cats, dogs, planes, and even hot dogs). It is completely possible to use feedforward neural networks on images, where each pixel is a feature. However, when doing so we run into two major problems.\n",
    "\n",
    "First, a feedforward neural networks do not take into account the spatial structure of the pixels. For example, in a 10x10 pixel image we might convert it into a vector of 100 pixel features, and in this case feedforward would consider the first feature (e.g. pixel value) to have the same relationship with the 10th feature as the 11th feature. However, in reality the 10th feature represents a pixel on the far side of the image as the first feature, while the 11th feature represents the pixel immediately below the first pixel.\n",
    "\n",
    "Second, and relatedly, feedforward neural networks learn global relationships in the features instead of local patterns. In more practical terms, this means that feedforward neural networks are not able to detect an object regardless of where it appears in an image. For example, imagine we are training a neural network to recognize faces, these faces might appear anywhere in the image from the upper right to the middle to the lower left. The power of convolutional neural networks is their ability handle both of these issues (and others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K \n",
    "\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Set image information\n",
    "channels = 1   ###Greyascale image\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# Load data and target from MNIST data\n",
    "(train_data, train_target), (test_data, test_target) = mnist.load_data()\n",
    "\n",
    "# Reshape training image data into features\n",
    "train_data = train_data.reshape(train_data.shape[0], channels, height, width)\n",
    "\n",
    "# Reshape test image data into features\n",
    "test_data = test_data.reshape(test_data.shape[0], channels, height, width)\n",
    "\n",
    "# Rescale pixel intensity to between 0 and 1\n",
    "train_features = train_data / 255    ###Rescaling\n",
    "test_features = test_data / 255\n",
    "#print(test_target)  ##It was in form of numerical i.e 0 to 9\n",
    "\n",
    "# One-hot encode target\n",
    "train_target = np_utils.to_categorical(train_target)\n",
    "test_target = np_utils.to_categorical(test_target)\n",
    "number_of_classes = test_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start neural network\n",
    "network = Sequential()\n",
    "\n",
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(channels, width, height), activation='relu'))\n",
    "\n",
    "# Add max pooling layer with a 2x2 window    ####To reduce the dimensions\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add dropout layer              ###To avoid overfitting\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add layer to flatten input\n",
    "network.add(Flatten())\n",
    "\n",
    "# # Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='categorical_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 208s 3ms/step - loss: 0.6267 - accuracy: 0.8062 - val_loss: 0.1675 - val_accuracy: 0.9518\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1983 - accuracy: 0.9422 - val_loss: 0.0880 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x277d37f28c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network\n",
    "network.fit(train_features, # Features\n",
    "            train_target, # Target\n",
    "            epochs=2, # Number of epochs\n",
    "            verbose=1, # Don't print description after each epoch\n",
    "            batch_size=1000, # Number of observations per batch\n",
    "            validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(10,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize network architecture\n",
    "SVG(model_to_dot(network, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the visualization as a file\n",
    "plot_model(network, show_shapes=True, to_file='network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Weight Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load IMDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Neural Network Architecture With Weight Regularization\n",
    "In Keras, we can add a weight regularization by including using including kernel_regularizer=regularizers.l2(0.01) a later. In this example, 0.01 determines how much we penalize higher parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function and L2 regularization\n",
    "network.add(layers.Dense(units=16, \n",
    "                         activation='relu', \n",
    "                         kernel_regularizer=regularizers.l2(0.01),\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function and L2 regularization\n",
    "network.add(layers.Dense(units=16, \n",
    "                         kernel_regularizer=regularizers.l2(0.01),\n",
    "                         activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))# Compile neural network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Neural Network Architecture With Dropout Layer\n",
    "In Keras, we can implement dropout by added Dropout layers into our network architecture. Each Dropout layer will drop a user-defined hyperparameter of units in the previous layer every batch. Remember in Keras the input layer is assumed to be the first layer and not added using the add. Therefore, if we want to add dropout to the input layer, the layer we add in our is a dropout layer. This layer contains both the proportion of the input layer’s units to drop 0.2 and input_shape defining the shape of the observation data. Next, after we add a dropout layer with 0.5 after each of the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Recurrent Neural Network\n",
    "Oftentimes we have text data that we want to classify. While it is possible to use a type of convolutional network, we are going to focus on a more popular option: the recurrent neural network. The key feature of recurrent neural networks is that information loops back in the network. This gives recurrent neural networks a type of memory it can use to better understand sequential data. A popular choice type of recurrent neural network is the long short-term memory (LSTM) network which allows for information to loop backwards in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB data info :  [here](http://localhost:8888/edit/Desktop/Python_revision/Chris_Albon_Blog_Prac/Imdb_info.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of features we want   ###Here 1000 top words \n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) ###Only load the top 1000 words\n",
    "\n",
    "# Use padding or truncation to make each observation have 400 features\n",
    "###We will bound reviews at 400 words, truncating longer reviews and zero-padding shorter reviews\n",
    "train_features = sequence.pad_sequences(train_data, maxlen=400)\n",
    "test_features = sequence.pad_sequences(test_data, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "998\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of words\n",
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(train_data))))    ###hstack stacks arrays horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 238.71 words (176.493674)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in train_data]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an Embedding layer as the input layer, setting the vocabulary to 1000 , the word vector size to 1000 dimensions and the input_length to 400. The output of this first layer will be a 1000×400 sized matrix as discussed in the previous section.\n",
    "##### To convert positive integer representations of words into a word embedding(vector) we are using an Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "##Create LSTM Neural Network Architecture\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add an embedding layer\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n",
    "\n",
    "# Add a long short-term memory layer with 128 units\n",
    "network.add(layers.LSTM(units=128))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='Adam', # Adam optimization\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 514s 21ms/step - loss: 0.6885 - accuracy: 0.5744 - val_loss: 0.6648 - val_accuracy: 0.5848\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 448s 18ms/step - loss: 0.6387 - accuracy: 0.6776 - val_loss: 0.5750 - val_accuracy: 0.7560\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 353s 14ms/step - loss: 0.4534 - accuracy: 0.8021 - val_loss: 0.3999 - val_accuracy: 0.8274\n"
     ]
    }
   ],
   "source": [
    "# Train neural network  ##We use less no. of epochs as this models overfit easily\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target\n",
    "                      epochs=3, # Number of epochs  \n",
    "                      verbose=1, # Do not print description after each epoch\n",
    "                      batch_size=1000, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
